{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c3986e6",
   "metadata": {},
   "source": [
    "### Ejercicios del tema de Clasificación\n",
    "\n",
    "*Hugo Díaz Díaz* (*hdiazd00@estudiantes.unileon.es*)\n",
    "\n",
    "*Correo profesional: hugo.didi.contacto@gmail.com*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8aa4f80",
   "metadata": {},
   "source": [
    "## Parte teórica (opcional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e5d668",
   "metadata": {},
   "source": [
    "### 1. ¿Cuál es la profundidad aproximada de un Árbol de Decisión entrenado (sin restricciones) en un conjunto de entrenamiento con 1 millón de muestras?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dba45b",
   "metadata": {},
   "source": [
    "Cuando un árbol de decisión se entrena sin ninguna limitación, sigue dividiendo mientras encuentre una reducción de impureza. Como en cada división las muestras se van partiendo en subconjuntos cada vez más pequeños, el árbol va profundizando nivel a nivel hasta que ya no quedan mejoras posibles.\n",
    "\n",
    "Con un conjunto tan grande como uno de un millón de instancias, este proceso suele dar lugar a árboles profundos, con muchas decenas de niveles. Por tanto, la profundidad aproximada estará en ese orden: varias decenas de niveles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b7df43",
   "metadata": {},
   "source": [
    "### 2. La impureza Gini de un nodo, ¿es generalmente menor o mayor que la de su padre? ¿Es generalmente menor/mayor, o siempre menor/mayor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2626c89f",
   "metadata": {},
   "source": [
    "Cada división intenta reducir la impureza respecto al nodo padre, así que lo normal es que los hijos tengan una impureza menor. Sin embargo, no es estrictamente obligatorio que sea siempre menor en ambos hijos: lo que sí garantiza el algoritmo es que la impureza ponderada de los dos hijos será menor que la del padre. Por tanto, generalmente es menor, pero no siempre en todos los nodos individuales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b3bd92",
   "metadata": {},
   "source": [
    "### 3. Si un Árbol de Decisión está sobreajustando el conjunto de entrenamiento, ¿es una buena idea intentar disminuir `max_depth`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48c4990",
   "metadata": {},
   "source": [
    "Sí, totalmente. Reducir la profundidad máxima limita la complejidad del árbol y actúa como regularización, así que disminuir `max_depth` es una de las formas clásicas de combatir el *overfitting*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f913e623",
   "metadata": {},
   "source": [
    "### 4. Si un Árbol de Decisión se ajusta demasiado poco al conjunto de entrenamiento, ¿es una buena idea intentar escalar las características de entrada?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31de33b9",
   "metadata": {},
   "source": [
    "No, los árboles no dependen de la escala de los atributos, así que escalar no va a mejorar el ajuste. Si el modelo está infraajustando, lo adecuado sería relajar la regularización (permitir más profundidad, más hojas, etc.). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425412de",
   "metadata": {},
   "source": [
    "### 5. Si se tarda una hora en entrenar un Árbol de Decisión en un conjunto de entrenamiento que contiene 1 millón de instancias, ¿cuánto tiempo se tardará aproximadamente en entrenar otro Árbol de Decisión en un conjunto de entrenamiento que contiene 10 millones de instancias?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43896b5",
   "metadata": {},
   "source": [
    "El tiempo de entrenamiento de un árbol de decisión crece aproximadamente como $n \\cdot \\log n$, porque el árbol procesa todas las muestras y además su profundidad aumenta de forma logarítmica con el tamaño del dataset. Al pasar de 1 millón a 10 millones de instancias, el factor dominante es el salto lineal: multiplicas por diez la cantidad de datos. El término logarítmico también sube, pero muy poco (de unos 20 niveles a 23).\n",
    "\n",
    "En conjunto, el tiempo final será aproximadamente diez veces mayor, así que si antes tardaba 1 hora, con 10 millones tardará alrededor de unas 10 horas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0752a503",
   "metadata": {},
   "source": [
    "### 6. Si su conjunto de entrenamiento contiene 100.000 instancias, ¿acelerará el entrenamiento si establece `presort=True`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946e0e14",
   "metadata": {},
   "source": [
    "No. El preordenamiento solo es útil para datasets pequeños. A partir de unas decenas de miles de instancias, el coste del presort hace que en realidad vaya más lento. Con 100.000 muestras no aporta mejoras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50003a0",
   "metadata": {},
   "source": [
    "## Parte práctica (obligatoria)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae73cfbe",
   "metadata": {},
   "source": [
    "### 1. Entrena y ajusta un Árbol de Decisión para el conjunto de datos Moons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74ddafec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(42) \n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f4fb72",
   "metadata": {},
   "source": [
    "#### a) Genera un conjunto de datos Moons utilizando make_moons(`n_samples=10000`, `noise=0.4`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe6ca7f",
   "metadata": {},
   "source": [
    "Lo primero es generar el dataset sintético tipo “moons” con bastante ruido para que el problema no sea trivial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f95caeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 2) (10000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "\n",
    "# Genero el conjunto de datos Moons con 10.000 muestras y ruido 0.4\n",
    "X, y = make_moons(n_samples=10000, noise=0.4, random_state=42)\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99acfb3f",
   "metadata": {},
   "source": [
    "Esto representan 10.000 puntos bidimensionales y sus etiquetas binarias correspondientes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebe8ba4",
   "metadata": {},
   "source": [
    "#### b) Divídelo en un conjunto de entrenamiento y un conjunto de test usando `train_test_split()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68009db3",
   "metadata": {},
   "source": [
    "Ahora divido los datos en train y test. Uso un 80/20 típico y fijo también `random_state` para que la partición sea estable. Aprovecho para estratificar según la clase y mantener proporciones similares en ambos conjuntos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e34ff069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 2) (2000, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Divido en entrenamiento y test, 80% / 20%\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd6b795",
   "metadata": {},
   "source": [
    "Con esto ya está listo el entorno básico: datos generados y partición hecha."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacf760b",
   "metadata": {},
   "source": [
    "#### c) Utiliza `GridSearchCV` para encontrar buenos valores de hiperparámetros para un `DecisionTreeClassifier`. Sugerencia: pruebe varios valores para `max_leaf_nodes`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b6c72b",
   "metadata": {},
   "source": [
    "#### d) Entrénalo con el conjunto de entrenamiento completo utilizando estos hiperparámetros y mide el rendimiento de su modelo en el conjunto de pruebas. Debería obtener entre un 85% y un 87% de exactitud."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db8277b",
   "metadata": {},
   "source": [
    "### 2. Cultivar un bosque."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d21177",
   "metadata": {},
   "source": [
    "#### a) Continuando con el ejercicio anterior, genere 1.000 subconjuntos del conjunto de entrenamiento, cada uno con 100 muestras seleccionadas aleatoriamente. Sugerencia: para ello puedes utilizar la clase `ShuffleSplit` de Scikit-Learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5e8177",
   "metadata": {},
   "source": [
    "#### b) Entrena un Árbol de Decisión en cada subconjunto, utilizando los mejores valores de hiperparámetros encontrados anteriormente. Evalúe estos 1.000 árboles de decisión en el conjunto de test. Dado que fueron entrenados en conjuntos más pequeños, estos Árboles de Decisión probablemente funcionarán peor que el primer Árbol de Decisión, alcanzando sólo un 80% de exactitud."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5784c188",
   "metadata": {},
   "source": [
    "#### c) Para cada muestra, genera las predicciones de los 1.000 árboles de decisión y conserva sólo la predicción más frecuente (puedes usar la función `mode()` de SciPy). Así obtendrás predicciones mayoritarias sobre el conjunto de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad2df32",
   "metadata": {},
   "source": [
    "#### d) Evalúa estas predicciones en el conjunto de test: deberías obtener una exactitud ligeramente superior a la de tu primer modelo (entre un 0,5 y un 1,5% más). Enhorabuena, has entrenado un clasificador Random Forest."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "decisiontrees",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
