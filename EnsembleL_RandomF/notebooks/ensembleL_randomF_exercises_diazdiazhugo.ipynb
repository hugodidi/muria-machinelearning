{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "275713c0",
   "metadata": {},
   "source": [
    "### Ejercicios del tema de Ensemble Learning y Random Forests\n",
    "\n",
    "*Hugo Díaz Díaz* (*hdiazd00@estudiantes.unileon.es*)\n",
    "\n",
    "*Correo profesional: hugo.didi.contacto@gmail.com*\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e359357c",
   "metadata": {},
   "source": [
    "## Parte teórica (opcional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0d5a16",
   "metadata": {},
   "source": [
    "### 1. Si has entrenado cinco modelos diferentes con exactamente los mismos datos de entrenamiento, y todos logran una precisión del 95%, ¿hay alguna posibilidad de combinar estos modelos para obtener mejores resultados? Si es así, ¿cómo? Si no, ¿por qué?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4160b4",
   "metadata": {},
   "source": [
    "Sí, se pueden combinar.\n",
    "Si los cinco modelos no cometen exactamente los mismos errores, es decir, son lo suficientemente diversos en cuanto a algoritmo, hiperparámetros inicializaciones... un ensemble (por ejemplo, un clasificador de votación dura o suave) puede mejorar un poco la precisión respecto a cada modelo individual, porque promediar las predicciones reduce la varianza del sistema. Si fueran prácticamente idénticos, la mejora sería nula."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c60c6db",
   "metadata": {},
   "source": [
    "### 2. ¿Cuál es la diferencia entre clasificadores de voto duro y voto suave?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb6bb0a",
   "metadata": {},
   "source": [
    "En voto duro cada modelo da una clase y la salida final es la clase más votada. En voto suave, cada modelo da probabilidades por clase, se promedian esas probabilidades y se elige la de mayor probabilidad media. El voto suave suele ir mejor porque tiene en cuenta el grado de confianza de los modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c70245",
   "metadata": {},
   "source": [
    "### 3. ¿Es posible acelerar el entrenamiento de un ensemble de bagging distribuyéndolo entre múltiples servidores? ¿Qué pasa con los ensembles de pasting, boosting, random forests o stacking?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3460f04",
   "metadata": {},
   "source": [
    "En bagging y pasting cada modelo se entrena de forma independiente en un subconjunto de datos, así que se pueden repartir entre varios núcleos/servidores sin problema. Lo mismo vale para los Random Forests, que son básicamente bagging de árboles. En boosting (AdaBoost, Gradient Boosting) los modelos se entrenan secuencialmente, cada uno corrige al anterior, así que no se puede paralelizar la secuencia. En stacking, los modelos base sí se pueden entrenar en paralelo, pero el meta-modelo va después con sus salidas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f016e6",
   "metadata": {},
   "source": [
    "### 4. ¿Cuál es el beneficio de la evaluación out-of-bag?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae784f2c",
   "metadata": {},
   "source": [
    "En bagging, cada modelo solo ve alrededor del 63 % de las instancias de entrenamiento, el resto se consideran out-of-bag para ese modelo. Eso permite usarlas como “test interno” sin tener que reservar un conjunto de validación separado, aprovechando todos los datos tanto para entrenar como para estimar el rendimiento del ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82b121b",
   "metadata": {},
   "source": [
    "### 5. ¿Qué hace que los Extra-Trees sean más aleatorios que los Random Forests regulares? ¿Cómo puede ayudar esta aleatoriedad extra? ¿Son los Extra-Trees más lentos o más rápidos que los Random Forests regulares?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5424aff",
   "metadata": {},
   "source": [
    "Los Extra-Trees son más aleatorios porque, además de muestrear características como en un Random Forest, eligen los umbrales de corte de forma totalmente aleatoria en cada nodo, en vez de buscar el mejor split. Esta aleatoriedad extra reduce la correlación entre árboles, baja la varianza (aunque suba un poco el sesgo) y suele mejorar la generalización. Al no buscar el mejor umbral, suelen ser más rápidos de entrenar que un Random Forest estándar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb11c54",
   "metadata": {},
   "source": [
    "### 6. Si tu ensemble de AdaBoost subajusta los datos de entrenamiento, ¿qué hiperparámetros deberías ajustar y cómo?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eae3983",
   "metadata": {},
   "source": [
    "Si mi ensemble de **AdaBoost** está subajustando (no llega a aprender bien ni siquiera el conjunto de entrenamiento), lo que necesito es darle más capacidad al modelo. Desde el punto de vista de los hiperparámetros, las opciones típicas son:\n",
    "\n",
    "- Aumentar `n_estimators`, es decir, añadir más clasificadores débiles al ensemble para que tenga más pasos de corrección de errores. \n",
    "\n",
    "- Hacer el estimador base algo más complejo (por ejemplo, árboles con mayor `max_depth` en lugar de simples decision stumps).\n",
    "\n",
    "- Y, si sigo muy corto, se puede subir ligeramente `learning_rate`, porque una tasa de aprendizaje muy baja actúa como una regularización fuerte y puede estar frenando demasiado las correcciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7fb503",
   "metadata": {},
   "source": [
    "### 7. Si tu ensemble de Gradient Boosting sobreajusta el conjunto de entrenamiento, ¿deberías aumentar o disminuir la tasa de aprendizaje?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319fc004",
   "metadata": {},
   "source": [
    "En **Gradient Boosting**, el hiperparámetro `learning_rate` controla cuánto corrige cada nuevo árbol los errores de los anteriores. Un valor alto hace que cada árbol “empuje” mucho y es fácil que el modelo sobreajuste al conjunto de entrenamiento. Cuando veo overfitting, lo que debo hacer es disminuir la tasa de aprendizaje y, en compensación, permitir más árboles (`n_estimators` más grande). En las transparencias se comenta precisamente que valores bajos de `learning_rate` requieren más árboles pero tienden a generalizar mejor gracias a esta estrategia de *shrinkage*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cb693e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f1f43d",
   "metadata": {},
   "source": [
    "## Parte práctica (obligatoria)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a56074",
   "metadata": {},
   "source": [
    "### Ejercicio 8\n",
    "\n",
    "Carga los datos MNIST (introducidos en el Capítulo 3) y divídelos en un conjunto de entrenamiento, un conjunto de validación y un conjunto de prueba (por ejemplo, usa 50,000 instancias para entrenamiento, 10,000 para validación y 10,000 para prueba).\n",
    "\n",
    "- Luego entrena varios clasificadores, como un clasificador Random Forest, un clasificador Extra-Trees y un SVM.\n",
    "- A continuación, intenta combinarlos en un ensemble que supere a todos en el conjunto de validación, utilizando un clasificador de voto suave o duro.\n",
    "- Una vez que hayas encontrado uno, pruébalo en el conjunto de prueba.\n",
    "- ¿Cuánto mejor se desempeña en comparación con los clasificadores individuales?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f306893",
   "metadata": {},
   "source": [
    "Primero se cargan los datos de MNIST desde `fetch_openml`. Después se normalizan las imágenes y se realiza la partición en conjuntos de entrenamiento, validación y prueba con el esquema 50k/10k/10k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b870187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "import os\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"ensembles\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62faf469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 784), (10000, 784), (10000, 784))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "\n",
    "X = mnist[\"data\"]\n",
    "y = mnist[\"target\"].astype(np.uint8)  # etiquetas como enteros\n",
    "\n",
    "# Normalización sencilla [0, 1]\n",
    "X = X / 255.0\n",
    "\n",
    "# División 60k / 10k (como en el libro) y luego 50k / 10k / 10k\n",
    "X_train_full, X_test = X[:60000], X[60000:]\n",
    "y_train_full, y_test = y[:60000], y[60000:]\n",
    "\n",
    "X_train, X_val = X_train_full[:50000], X_train_full[50000:]\n",
    "y_train, y_val = y_train_full[:50000], y_train_full[50000:]\n",
    "\n",
    "X_train.shape, X_val.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25bbb46",
   "metadata": {},
   "source": [
    "En la siguiente celda se definen tres clasificadores distintos sobre el conjunto de entrenamiento: un Random Forest, un Extra-Trees y un SVM con kernel RBF. Para que el SVM sea computacionalmente manejable, se entrena sobre un subconjunto del conjunto de entrenamiento, mientras que la validación se hace siempre sobre las 10.000 instancias de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d1151f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelos base: Random Forest, Extra-Trees y SVM\n",
    "rf_clf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_features=\"sqrt\",\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "et_clf = ExtraTreesClassifier(\n",
    "    n_estimators=100,\n",
    "    max_features=\"sqrt\",\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Para el SVM se usa un subconjunto del entrenamiento por coste computacional\n",
    "svm_train_size = 10000\n",
    "X_train_svm = X_train[:svm_train_size]\n",
    "y_train_svm = y_train[:svm_train_size]\n",
    "\n",
    "svm_clf = SVC(\n",
    "    kernel=\"rbf\",\n",
    "    gamma=\"scale\",\n",
    "    C=10,\n",
    "    probability=True,  # necesario para voto suave\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0744642",
   "metadata": {},
   "source": [
    "A continuación, se entrenan los modelos con sus respectivos datos de entrenamiento y se evalúan en el conjunto de validación, de forma que se tenga una referencia del rendimiento individual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f075548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9734, 0.9743, 0.9706)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenamiento de los modelos individuales\n",
    "rf_clf.fit(X_train, y_train)\n",
    "et_clf.fit(X_train, y_train)\n",
    "svm_clf.fit(X_train_svm, y_train_svm)\n",
    "\n",
    "# Evaluación en el conjunto de validación\n",
    "y_val_pred_rf = rf_clf.predict(X_val)\n",
    "y_val_pred_et = et_clf.predict(X_val)\n",
    "y_val_pred_svm = svm_clf.predict(X_val)\n",
    "\n",
    "val_acc_rf = accuracy_score(y_val, y_val_pred_rf)\n",
    "val_acc_et = accuracy_score(y_val, y_val_pred_et)\n",
    "val_acc_svm = accuracy_score(y_val, y_val_pred_svm)\n",
    "\n",
    "val_acc_rf, val_acc_et, val_acc_svm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9a405f",
   "metadata": {},
   "source": [
    "En este punto se dispone de las precisiones en validación de cada clasificador por separado. Los resultados obtenidos han sido aproximadamente 0.9734 para Random Forest, 0.9743 para Extra-Trees y 0.9706 para el SVM. Aunque Extra-Trees destaca ligeramente, las tres métricas son muy similares y ya bastante altas, lo que indica que todos los modelos capturan bien la estructura del problema. Aun así, es razonable pensar que sus errores no son totalmente coincidentes, especialmente entre los modelos basados en árboles y el SVM, por lo que la combinación de sus predicciones puede aportar una mejora adicional.\n",
    "\n",
    "El siguiente paso consiste, por tanto, en construir un ensemble de votación que combine estos modelos. Se intentó utilizar un `VotingClassifier` con voto suave, ya que aprovecha las probabilidades de los modelos base y suele ofrecer un rendimiento algo superior. Sin embargo, dado que el SVM se reentrena internamente sobre las 50.000 instancias cuando se llama a fit() del VotingClassifier, el tiempo de cómputo se vuelve excesivo. Por ello, se opta por implementar manualmente el voto suave: se obtienen las probabilidades `predict_proba` de cada clasificador base, se promedian y se escoge la clase con mayor probabilidad media, reproduciendo el comportamiento del voto suave sin forzar un nuevo entrenamiento costoso del SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b9b42593",
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_voting_predict(models, X):\n",
    "    \"\"\"\n",
    "    Realiza voto suave a partir de una lista de modelos que implementan predict_proba.\n",
    "    Devuelve las clases predichas por el ensemble.\n",
    "    \"\"\"\n",
    "    # Se acumulan las probabilidades de cada modelo\n",
    "    proba_list = [clf.predict_proba(X) for clf in models]\n",
    "    avg_proba = np.mean(proba_list, axis=0)\n",
    "    # Se escoge la clase con mayor probabilidad media\n",
    "    return np.argmax(avg_proba, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772a902f",
   "metadata": {},
   "source": [
    "A continuación se evalúa este ensemble de voto suave sobre el conjunto de validación y se compara su precisión con la de los clasificadores individuales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "083e97bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9734, 0.9743, 0.9706, 0.9759)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensemble de voto suave sobre el conjunto de validación\n",
    "base_models = [rf_clf, et_clf, svm_clf]\n",
    "\n",
    "y_val_pred_ensemble = soft_voting_predict(base_models, X_val)\n",
    "val_acc_ensemble = accuracy_score(y_val, y_val_pred_ensemble)\n",
    "\n",
    "val_acc_rf, val_acc_et, val_acc_svm, val_acc_ensemble\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f3cf59",
   "metadata": {},
   "source": [
    "En nuestro caso concreto, las precisiones en validación han sido 97,34% para Random Forest, 97,43% para Extra-Trees y 97,06% para el SVM, mientras que el ensemble de voto suave alcanza 97,59%. Es decir, el ensemble mejora ligeramente al mejor modelo individual (Extra-Trees) en unas dos décimas porcentuales, lo que confirma que los modelos aportan información complementaria y que la agregación de sus probabilidades permite corregir algunos errores que cometen por separado.\n",
    "\n",
    "Una vez comprobado que el ensemble funciona bien en validación, el siguiente paso consiste en evaluar tanto los modelos individuales como el ensemble sobre el conjunto de prueba, usando exactamente los modelos ya entrenados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "755b3f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.968, 0.9703, 0.9684, 0.9721)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluación de los modelos individuales en el conjunto de prueba\n",
    "y_test_pred_rf = rf_clf.predict(X_test)\n",
    "y_test_pred_et = et_clf.predict(X_test)\n",
    "y_test_pred_svm = svm_clf.predict(X_test)\n",
    "\n",
    "test_acc_rf = accuracy_score(y_test, y_test_pred_rf)\n",
    "test_acc_et = accuracy_score(y_test, y_test_pred_et)\n",
    "test_acc_svm = accuracy_score(y_test, y_test_pred_svm)\n",
    "\n",
    "# Evaluación del ensemble de voto suave en el conjunto de prueba\n",
    "y_test_pred_ensemble = soft_voting_predict(base_models, X_test)\n",
    "test_acc_ensemble = accuracy_score(y_test, y_test_pred_ensemble)\n",
    "\n",
    "test_acc_rf, test_acc_et, test_acc_svm, test_acc_ensemble\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed539d3",
   "metadata": {},
   "source": [
    "En los resultados obtenidos en el conjunto de prueba, las precisiones han sido 96,8% para Random Forest, 97,03% para Extra-Trees y 96,84% para el SVM, mientras que el ensemble de voto suave alcanza 97,21%. Es decir, el ensemble mejora ligeramente al mejor modelo individual (Extra-Trees) en unas pocas décimas, cumpliendo el objetivo del ejercicio: se consigue un rendimiento algo superior y un comportamiento más estable que cualquiera de los clasificadores por separado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d70977",
   "metadata": {},
   "source": [
    "## Ejercicio 9\n",
    "\n",
    "Ejecuta los clasificadores individuales del ejercicio anterior para hacer predicciones en el conjunto de validación, y crea un nuevo conjunto de entrenamiento con las predicciones resultantes:\n",
    "\n",
    "- Cada instancia de entrenamiento es un vector que contiene el conjunto de predicciones de todos tus clasificadores para una imagen, y el objetivo es la clase de la imagen.\n",
    "- Entrena un clasificador en este nuevo conjunto de entrenamiento. ¡Felicidades, acabas de entrenar un blender, y junto con los clasificadores forman un ensemble de stacking! Ahora evaluemos el ensemble en el conjunto de prueba.\n",
    "- Para cada imagen en el conjunto de prueba, haz predicciones con todos tus clasificadores, luego alimenta las predicciones al blender para obtener las predicciones del ensemble.\n",
    "- ¿Cómo se compara con el clasificador de votación que entrenaste anteriormente?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ensemblel-randomf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
