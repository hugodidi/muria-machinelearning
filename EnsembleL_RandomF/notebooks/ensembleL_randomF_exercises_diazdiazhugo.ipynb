{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "275713c0",
   "metadata": {},
   "source": [
    "### Ejercicios del tema de Ensemble Learning y Random Forests\n",
    "\n",
    "*Hugo Díaz Díaz* (*hdiazd00@estudiantes.unileon.es*)\n",
    "\n",
    "*Correo profesional: hugo.didi.contacto@gmail.com*\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e359357c",
   "metadata": {},
   "source": [
    "## Parte teórica (opcional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0d5a16",
   "metadata": {},
   "source": [
    "### 1. Si has entrenado cinco modelos diferentes con exactamente los mismos datos de entrenamiento, y todos logran una precisión del 95%, ¿hay alguna posibilidad de combinar estos modelos para obtener mejores resultados? Si es así, ¿cómo? Si no, ¿por qué?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4160b4",
   "metadata": {},
   "source": [
    "Sí, se pueden combinar.\n",
    "Si los cinco modelos no cometen exactamente los mismos errores, es decir, son lo suficientemente diversos en cuanto a algoritmo, hiperparámetros inicializaciones... un ensemble (por ejemplo, un clasificador de votación dura o suave) puede mejorar un poco la precisión respecto a cada modelo individual, porque promediar las predicciones reduce la varianza del sistema. Si fueran prácticamente idénticos, la mejora sería nula."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c60c6db",
   "metadata": {},
   "source": [
    "### 2. ¿Cuál es la diferencia entre clasificadores de voto duro y voto suave?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb6bb0a",
   "metadata": {},
   "source": [
    "En voto duro cada modelo da una clase y la salida final es la clase más votada. En voto suave, cada modelo da probabilidades por clase, se promedian esas probabilidades y se elige la de mayor probabilidad media. El voto suave suele ir mejor porque tiene en cuenta el grado de confianza de los modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c70245",
   "metadata": {},
   "source": [
    "### 3. ¿Es posible acelerar el entrenamiento de un ensemble de bagging distribuyéndolo entre múltiples servidores? ¿Qué pasa con los ensembles de pasting, boosting, random forests o stacking?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3460f04",
   "metadata": {},
   "source": [
    "En bagging y pasting cada modelo se entrena de forma independiente en un subconjunto de datos, así que se pueden repartir entre varios núcleos/servidores sin problema. Lo mismo vale para los Random Forests, que son básicamente bagging de árboles. En boosting (AdaBoost, Gradient Boosting) los modelos se entrenan secuencialmente, cada uno corrige al anterior, así que no se puede paralelizar la secuencia. En stacking, los modelos base sí se pueden entrenar en paralelo, pero el meta-modelo va después con sus salidas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f016e6",
   "metadata": {},
   "source": [
    "### 4. ¿Cuál es el beneficio de la evaluación out-of-bag?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae784f2c",
   "metadata": {},
   "source": [
    "En bagging, cada modelo solo ve alrededor del 63 % de las instancias de entrenamiento, el resto se consideran out-of-bag para ese modelo. Eso permite usarlas como “test interno” sin tener que reservar un conjunto de validación separado, aprovechando todos los datos tanto para entrenar como para estimar el rendimiento del ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82b121b",
   "metadata": {},
   "source": [
    "### 5. ¿Qué hace que los Extra-Trees sean más aleatorios que los Random Forests regulares? ¿Cómo puede ayudar esta aleatoriedad extra? ¿Son los Extra-Trees más lentos o más rápidos que los Random Forests regulares?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5424aff",
   "metadata": {},
   "source": [
    "Los Extra-Trees son más aleatorios porque, además de muestrear características como en un Random Forest, eligen los umbrales de corte de forma totalmente aleatoria en cada nodo, en vez de buscar el mejor split. Esta aleatoriedad extra reduce la correlación entre árboles, baja la varianza (aunque suba un poco el sesgo) y suele mejorar la generalización. Al no buscar el mejor umbral, suelen ser más rápidos de entrenar que un Random Forest estándar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb11c54",
   "metadata": {},
   "source": [
    "### 6. Si tu ensemble de AdaBoost subajusta los datos de entrenamiento, ¿qué hiperparámetros deberías ajustar y cómo?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eae3983",
   "metadata": {},
   "source": [
    "Si mi ensemble de **AdaBoost** está subajustando (no llega a aprender bien ni siquiera el conjunto de entrenamiento), lo que necesito es darle más capacidad al modelo. Desde el punto de vista de los hiperparámetros, las opciones típicas son:\n",
    "\n",
    "- Aumentar `n_estimators`, es decir, añadir más clasificadores débiles al ensemble para que tenga más pasos de corrección de errores. \n",
    "\n",
    "- Hacer el estimador base algo más complejo (por ejemplo, árboles con mayor `max_depth` en lugar de simples decision stumps).\n",
    "\n",
    "- Y, si sigo muy corto, se puede subir ligeramente `learning_rate`, porque una tasa de aprendizaje muy baja actúa como una regularización fuerte y puede estar frenando demasiado las correcciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7fb503",
   "metadata": {},
   "source": [
    "### 7. Si tu ensemble de Gradient Boosting sobreajusta el conjunto de entrenamiento, ¿deberías aumentar o disminuir la tasa de aprendizaje?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319fc004",
   "metadata": {},
   "source": [
    "En **Gradient Boosting**, el hiperparámetro `learning_rate` controla cuánto corrige cada nuevo árbol los errores de los anteriores. Un valor alto hace que cada árbol “empuje” mucho y es fácil que el modelo sobreajuste al conjunto de entrenamiento. Cuando veo overfitting, lo que debo hacer es disminuir la tasa de aprendizaje y, en compensación, permitir más árboles (`n_estimators` más grande). En las transparencias se comenta precisamente que valores bajos de `learning_rate` requieren más árboles pero tienden a generalizar mejor gracias a esta estrategia de *shrinkage*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cb693e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f1f43d",
   "metadata": {},
   "source": [
    "## Parte práctica (obligatoria)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a56074",
   "metadata": {},
   "source": [
    "### Ejercicio 8\n",
    "\n",
    "Carga los datos MNIST (introducidos en el Capítulo 3) y divídelos en un conjunto de entrenamiento, un conjunto de validación y un conjunto de prueba (por ejemplo, usa 50,000 instancias para entrenamiento, 10,000 para validación y 10,000 para prueba).\n",
    "\n",
    "- Luego entrena varios clasificadores, como un clasificador Random Forest, un clasificador Extra-Trees y un SVM.\n",
    "- A continuación, intenta combinarlos en un ensemble que supere a todos en el conjunto de validación, utilizando un clasificador de voto suave o duro.\n",
    "- Una vez que hayas encontrado uno, pruébalo en el conjunto de prueba.\n",
    "- ¿Cuánto mejor se desempeña en comparación con los clasificadores individuales?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f306893",
   "metadata": {},
   "source": [
    "Primero se cargan los datos de MNIST desde `fetch_openml`. Después se normalizan las imágenes y se realiza la partición en conjuntos de entrenamiento, validación y prueba con el esquema 50k/10k/10k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b870187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "import os\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"ensembles\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62faf469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 784), (10000, 784), (10000, 784))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "\n",
    "X = mnist[\"data\"]\n",
    "y = mnist[\"target\"].astype(np.uint8)  # etiquetas como enteros\n",
    "\n",
    "# Normalización sencilla [0, 1]\n",
    "X = X / 255.0\n",
    "\n",
    "# División 60k / 10k (como en el libro) y luego 50k / 10k / 10k\n",
    "X_train_full, X_test = X[:60000], X[60000:]\n",
    "y_train_full, y_test = y[:60000], y[60000:]\n",
    "\n",
    "X_train, X_val = X_train_full[:50000], X_train_full[50000:]\n",
    "y_train, y_val = y_train_full[:50000], y_train_full[50000:]\n",
    "\n",
    "X_train.shape, X_val.shape, X_test.shape\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ensemblel-randomf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
